{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T04:40:39.659159Z",
     "start_time": "2020-01-20T04:40:39.618026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entities': [{'confidence': 0.9960352006,\n",
      "               'end': 16,\n",
      "               'entity': 'cuisine',\n",
      "               'extractor': 'CRFEntityExtractor',\n",
      "               'start': 10,\n",
      "               'value': 'french'}],\n",
      " 'intent': {'confidence': 0.9999802113, 'name': 'inform'},\n",
      " 'intent_ranking': [{'confidence': 0.9999802113, 'name': 'inform'},\n",
      "                    {'confidence': 6.9449e-06, 'name': 'email_id'},\n",
      "                    {'confidence': 5.7164e-06, 'name': 'mood_unhappy'},\n",
      "                    {'confidence': 3.6971e-06, 'name': 'goodbye'},\n",
      "                    {'confidence': 1.2413e-06, 'name': 'bot_challenge'},\n",
      "                    {'confidence': 7.163e-07, 'name': 'greet'},\n",
      "                    {'confidence': 5.65e-07, 'name': 'mood_great'},\n",
      "                    {'confidence': 3.832e-07, 'name': 'order_now'},\n",
      "                    {'confidence': 2.54e-07, 'name': 'request_info'},\n",
      "                    {'confidence': 2.487e-07, 'name': 'thankyou'}],\n",
      " 'text': 'how about french food'}\n"
     ]
    }
   ],
   "source": [
    "from saai.multi_nlu_client import nlu_parse\n",
    "from pprint import pprint\n",
    "url='http://localhost:15008'\n",
    "result=await nlu_parse(url, 'how about french food')\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T04:40:57.016933Z",
     "start_time": "2020-01-20T04:40:56.996319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 10,\n",
       "  'end': 16,\n",
       "  'value': 'french',\n",
       "  'entity': 'cuisine',\n",
       "  'confidence': 0.9960352006,\n",
       "  'extractor': 'CRFEntityExtractor'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T06:22:22.653739Z",
     "start_time": "2020-01-20T06:22:22.633275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 10,\n",
       "  'end': 23,\n",
       "  'value': 'north eastern',\n",
       "  'entity': 'cuisine',\n",
       "  'confidence': 0.7435030861,\n",
       "  'extractor': 'CRFEntityExtractor'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from saai.tool import rasa_nlu_parse, rasa_nlu_vis\n",
    "# sents='how about street food'\n",
    "# sents='how about chinese food'\n",
    "sents='how about north eastern food'\n",
    "\n",
    "result=rasa_nlu_parse(sents, 'http://localhost:15008')\n",
    "ents = result['entities']\n",
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T06:22:35.914648Z",
     "start_time": "2020-01-20T06:22:35.803658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">how about <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">north eastern<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">cuisine</span></span> food</div>"
      ],
      "text/plain": [
       "BoxMarkup('how about north eastern food', [Span(10, 23, 'cuisine')])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rasa_nlu_vis(sents, 'http://localhost:15008')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T06:22:40.052417Z",
     "start_time": "2020-01-20T06:22:39.899794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('how', 'O'),\n",
       " ('about', 'O'),\n",
       " ('north', 'O'),\n",
       " ('eastern', 'O'),\n",
       " ('food', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagas.nlu.ruleset_procs import list_words, cached_chunks, get_main_domains\n",
    "from sagas.conf.conf import cf\n",
    "lang='en'\n",
    "chunks = cached_chunks(sents, lang, cf.engine(lang))\n",
    "[(w.text, w.entity or 'O') for w in chunks['doc'].words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T05:41:54.055440Z",
     "start_time": "2020-01-20T05:41:54.051815Z"
    }
   },
   "outputs": [],
   "source": [
    "# sents.index('xx', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T06:22:47.333245Z",
     "start_time": "2020-01-20T06:22:47.315485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('how', '1'), ('about', '2'), ('north', '3'), ('eastern', '4'), ('food', '5'), ('.', '6')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1': (0, 3), '2': (4, 9), '3': (10, 15), '4': (16, 23), '5': (24, 28)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_word_positions(doc):\n",
    "    running_offset = 0\n",
    "    rs = []\n",
    "    pos_map={}\n",
    "    for token in doc.words:\n",
    "        word = token.text    \n",
    "        word_offset = sents.find(word, running_offset)\n",
    "        if word_offset>-1:\n",
    "            word_len = len(word)\n",
    "            running_offset = word_offset + word_len\n",
    "            pos_map[token.index]=(word_offset, running_offset)\n",
    "    return pos_map\n",
    "\n",
    "pos_map=set_word_positions(chunks['doc'])\n",
    "print([(w.text, w.index) for w in chunks['doc'].words])\n",
    "pos_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T06:22:53.612073Z",
     "start_time": "2020-01-20T06:22:53.596104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how - (0, 3)\n",
      "about - (4, 9)\n",
      "north - (10, 15)\n",
      "eastern - (16, 23)\n",
      "food - (24, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'start': 10, 'end': 15, 'value': 'north', 'entity': 'cuisine'},\n",
       " {'start': 16, 'end': 23, 'value': 'eastern', 'entity': 'cuisine'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_offset = 0\n",
    "rs = []\n",
    "for token in chunks['doc'].words:\n",
    "    word = token.text    \n",
    "    word_offset = sents.find(word, running_offset)\n",
    "    if word_offset>-1:\n",
    "        word_len = len(word)\n",
    "        running_offset = word_offset + word_len\n",
    "        print(f\"{word} - ({word_offset}, {running_offset})\")\n",
    "        for ent in ents:\n",
    "            start, end=ent['start'], ent['end']\n",
    "            if word_offset>=start and running_offset<=end:\n",
    "                rs.append({\"start\": word_offset,\n",
    "                           \"end\": running_offset,\n",
    "                           'value': word,\n",
    "                           'entity': ent['entity']\n",
    "                           })\n",
    "rs            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T06:23:06.046651Z",
     "start_time": "2020-01-20T06:23:06.040089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "for ent in ents:\n",
    "    word=ent['value']\n",
    "    word_offset = sents.index(word, ent['start'])\n",
    "    print(word_offset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
